# Binary Cross-Entropy

**Q:** What is binary cross-entropy loss?

**A:**

- BCE = -[y·log(p) + (1-y)·log(1-p)]
- Standard for binary classification
- Penalizes confident wrong predictions heavily
- Works with sigmoid output
- Avoids learning slowdown when sigmoid saturates

**See also:** [[202101120828 Cross-Entropy Cost]], [[202012261450 Sigmoid Neuron]]

---
