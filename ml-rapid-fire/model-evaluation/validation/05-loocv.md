# Leave-One-Out Cross-Validation (LOOCV)

**Q:** What is LOOCV and what are its tradeoffs?

**A:**

- k-fold where k = n (each sample is its own fold)
- Pro: maximum training data used
- Con: computationally expensive (n model fits)
- Con: high variance in estimate
- Use for very small datasets

**See also:** [[202107270653 Model Selection for Linear Regression]], [[202101080742 Cross Validation (K-Fold)]]

---
