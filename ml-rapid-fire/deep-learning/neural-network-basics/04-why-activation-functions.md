# Why Activation Functions?

**Q:** Why do neural networks need activation functions?

**A:**

- Without them, network is just **linear transformation**
- Stacking linear layers = still linear (can't learn complex patterns)
- Activation adds **nonlinearity**
- Enables learning of curved decision boundaries

---
