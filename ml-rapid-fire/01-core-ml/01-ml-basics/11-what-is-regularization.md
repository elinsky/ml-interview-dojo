# What is Regularization?

**Q:** What is regularization and why is it used?

**A:**

- **Penalty term** added to the loss function: Cost(h) = EmpLoss(h) + λ·Complexity(h)
- **Discourages complex hypotheses**
- **Prevents overfitting**
- Examples: L1 (Lasso), L2 (Ridge), Dropout

"Regularization is the process of selecting a hypothesis that minimizes both the empirical loss and the complexity of the hypothesis." [@russell2010artificial, p. 713] — 202104170846 Regularization

---
