# Intrinsic Motivation

**Q:** What is intrinsic motivation and why is it useful in RL?
- Concept
- Types
- Why needed

**A:**

- **Concept**: internal reward signal encouraging exploration (beyond external reward)
  - Bonus for visiting novel states, learning new things
  - Agent curious about environment
- **Types**:
  - **Curiosity**: reward for prediction error (surprising states)
  - **Count-based**: reward inversely related to visit count
  - **Information gain**: reward for reducing uncertainty about world
  - **Random network distillation (RND)**: reward for states neural network hasn't seen
- **Why needed**:
  - Sparse reward environments (reward rare, exploration critical)
  - Hard exploration problems (Montezuma's Revenge)
  - Encourages systematic coverage of state space
- **Implementation**: r_total = r_extrinsic + β × r_intrinsic
- **Risk**: agent may seek novelty for its own sake, ignore task

---
