# Softmax (Boltzmann) Exploration

**Q:** How does softmax exploration work?
- Formula
- Temperature parameter
- Comparison to ε-greedy

**A:**

- **Formula**:
  - P(a) = exp(Q(a)/τ) / Σ exp(Q(a')/τ)
  - Probability of action proportional to exponentiated value
- **Temperature parameter τ**:
  - τ → ∞: uniform random (all actions equally likely)
  - τ → 0: greedy (always best action)
  - Higher τ = more exploration
- **Comparison to ε-greedy**:
  - Softmax: considers action values, prefers better actions even when exploring
  - ε-greedy: uniform random exploration ignores values
  - Softmax: smoother action selection
- **Temperature annealing**: start high, decrease τ over time
- **Limitation**: sensitive to value scale (need to rescale if values change magnitude)
- **Used in**: policy representation in RL, AlphaGo move selection

---
