# Regret Bounds

**Q:** What are regret bounds and what do they tell us?
- Definition
- Common bounds
- Practical implications

**A:**

- **Definition**:
  - Regret R_T = Σ(μ* - μ_{a_t})
  - Sum of differences from optimal arm over T rounds
  - Measures exploration "cost"
- **Common bounds** (for K-armed bandits):
  - Random: O(T) — linear regret (bad)
  - ε-greedy: O(T) with constant ε, O(√T) with proper decay
  - UCB: O(√KT log T) or O(K log T / Δ) — depends on gap Δ
  - Thompson: O(√KT log T) — matches UCB order
  - Lower bound: Ω(√KT) — can't do better
- **Practical implications**:
  - Sublinear regret: learning is happening
  - Log regret possible when gaps between arms are known/large
  - More arms K → more exploration needed
- **Finance**: opportunity cost of learning vs exploiting trading strategy

---
